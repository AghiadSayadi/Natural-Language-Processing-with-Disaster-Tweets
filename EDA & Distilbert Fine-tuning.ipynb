{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf62e88-c3b9-4373-a3ee-49245a215f43",
   "metadata": {},
   "source": [
    "## 28-May 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef754bd-1cf1-4140-aed9-0cfc21d91c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import string\n",
    "import alphabet_detector\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import nltk.corpus\n",
    "import seaborn as sn\n",
    "import matplotlib.pylab as plt\n",
    "import cleantext\n",
    "\n",
    "from cleantext import clean\n",
    "from tensorflow import keras\n",
    "from nltk.corpus import stopwords\n",
    "from alphabet_detector import AlphabetDetector\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f25123ae-461b-4d5b-a8ac-8898bc2bd6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0541f39c-ab1f-40ce-8b62-8c293319e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories = ['Disaster', 'NoDisaster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c0bd42-914b-4e9a-89c2-c23f749db509",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) ## Helps in reading the entire text\n",
    "df = pd.read_csv('train.csv')\n",
    "df.drop(columns=['id', 'keyword', 'location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7f1495-8ab3-4060-a3ef-44f47ffef10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79fbcea6-7bf7-4101-a7b5-7f7d4f97b81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "# No NaN values in our text and target columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0538b-c2b6-4690-a1ba-374281abd84e",
   "metadata": {},
   "source": [
    "### Cleaning Functions Defenition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee1d0a4-97e3-42c5-8104-ca769163efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "stop = stopwords.words('english')\n",
    "def remove_symbols(text):\n",
    "    pattern = r'[' + string.punctuation + ']'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    if text[-1] == ' ':\n",
    "        text = text[:-1]\n",
    "    if text[0] == ' ':\n",
    "        text = text[1:]\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('[0-9]', '',text)\n",
    "\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_non_ASCII(text):\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "\n",
    "def clean_text(text):\n",
    "    #text = re.sub('\\\\n', '', text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_symbols(text)\n",
    "    text = lower_case(text)\n",
    "    text = remove_non_ASCII(text)\n",
    "    text = remove_extra_spaces(text)\n",
    "    text = remove_links(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d5c2db-ee35-4b01-ae5d-a090150567a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function defined above to our text\n",
    "df.text=df.text.apply(lambda x:clean_text(x))\n",
    "\n",
    "# Removing stopwords\n",
    "df.text = df.text.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "# Get rid of text with zero words\n",
    "df = df[df['text'].str.split().str.len().ge(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71ab948b-9c7d-407e-8b30-5a725241439f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>residents asked shelter place notified officers evacuation shelter place orders expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfires evacuation orders california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pours school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       text  \\\n",
       "0                                              deeds reason earthquake may allah forgive us   \n",
       "1                                                     forest fire near la ronge sask canada   \n",
       "2  residents asked shelter place notified officers evacuation shelter place orders expected   \n",
       "3                                     people receive wildfires evacuation orders california   \n",
       "4                                   got sent photo ruby alaska smoke wildfires pours school   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe496e3-9281-4793-884e-06d741298d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Sentences Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.114804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.502564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Train Sentences Length\n",
       "count             7613.000000\n",
       "mean                 9.114804\n",
       "std                  3.502564\n",
       "min                  1.000000\n",
       "25%                  6.000000\n",
       "50%                  9.000000\n",
       "75%                 12.000000\n",
       "90%                 14.000000\n",
       "95%                 15.000000\n",
       "99%                 17.000000\n",
       "max                 23.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Information about the dataset\n",
    "df_length_train = pd.DataFrame(columns=['Train Sentences Length'])\n",
    "length_list_train = []\n",
    "for i in range (len(df.text)):\n",
    "    length_list_train.append((len(df['text'][i].split()))) \n",
    "df_length_train['Train Sentences Length'] = length_list_train\n",
    "df_length_train.describe(percentiles=[.25, .5, .75, .90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2d17e-2497-4081-8f28-42854ba84dd7",
   "metadata": {},
   "source": [
    " Since maximum is 23, we will set our sequence length below to be 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6bdda75-11fe-46f0-a999-4c9757bce464",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle dataset & reset index\n",
    "df=df.sample(frac=1)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f166fac9-6d4d-4c45-9e66-dc19d2274cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 20% of the train data for validation\n",
    "train = df\n",
    "n = int(len(train)*0.20)\n",
    "val = train[:n]\n",
    "train = train[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4dccd1e-6576-4a61-be2f-449d73ee6cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6091, 2)\n",
      "(1522, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5cee3-fd7c-4bda-9d9a-4162c8b1755e",
   "metadata": {},
   "source": [
    "### Loading Distilbert tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99a7b48-d107-474d-8abe-db4192ff9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19613f5-0446-439b-93db-6c39b3c2dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 15% \n",
    "n = int(len(train)*0.15)\n",
    "val = train[:n]\n",
    "train = train[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0246e81-e3b8-44c6-af3e-bb490130a040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5178, 2)\n",
      "(913, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "425e4d89-1802-441d-99ac-4530e8d0a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 23  # we will cut/pad our sequences to a length of 23 tokens\n",
    "BATCH_SIZE = 16  # we will use batches of 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6bb14-3b19-4f2b-9b60-ec253625602b",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0da68b3a-7790-43a0-8faf-ff6a36d4a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    tokens = tokenizer.encode_plus(sentence, max_length=SEQ_LEN,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_attention_mask=True,\n",
    "                                   return_token_type_ids=False, return_tensors='tf')\n",
    "    return tokens['input_ids'], tokens['attention_mask']\n",
    "\n",
    "# initialize two arrays for input tensors\n",
    "Xids = np.zeros((len(train), SEQ_LEN))\n",
    "Xmask = np.zeros((len(train), SEQ_LEN))\n",
    "\n",
    "for i, sentence in enumerate(train['text']):\n",
    "    Xids[i, :], Xmask[i, :] = tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e87825af-8ec7-4142-b3fc-4ed9b703c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = train['target'].values  # take sentiment column in df as array\n",
    "labels = np.zeros((arr.size, arr.max()+1))  # initialize empty (all zero) label array\n",
    "labels[np.arange(arr.size), arr] = 1  # add ones in indices where we have a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b857f07-c2cb-485d-9b80-ba7e89d83116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrays into tensorflow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
    "\n",
    "# create a mapping function that we use to restructure our dataset\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "\n",
    "# using map method to apply map_func to dataset\n",
    "dataset = dataset.map(map_func)\n",
    "\n",
    "# shuffle data and batch it\n",
    "dataset = dataset.shuffle(100000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb4dbc1-5e5a-4afb-b41e-b3620b52df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset\n",
    "del dataset ## To preserve memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e97395c-4eb4-4f24-86b8-f6cb5885ae26",
   "metadata": {},
   "source": [
    "## Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1da3f814-2650-48c3-800b-cd6a55db6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def tokenize(sentence):\n",
    "    tokens = tokenizer.encode_plus(sentence, max_length=SEQ_LEN,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_attention_mask=True,\n",
    "                                   return_token_type_ids=False, return_tensors='tf')\n",
    "    return tokens['input_ids'], tokens['attention_mask']\n",
    "\n",
    "# initialize two arrays for input tensors\n",
    "Xids = np.zeros((len(val), SEQ_LEN))\n",
    "Xmask = np.zeros((len(val), SEQ_LEN))\n",
    "\n",
    "for i, sentence in enumerate(val['text']):\n",
    "    Xids[i, :], Xmask[i, :] = tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27c27d58-2553-4ad8-a940-a31cd8c3ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = val['target'].values  # take sentiment column in df as array\n",
    "labels = np.zeros((arr.size, arr.max()+1))  # initialize empty (all zero) label array\n",
    "labels[np.arange(arr.size), arr] = 1  # add ones in indices where we have a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f3fd538-fa79-4e05-9687-2bd437735f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arrays into tensorflow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
    "\n",
    "# create a mapping function that we use to restructure our dataset\n",
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n",
    "\n",
    "# using map method to apply map_func to dataset\n",
    "dataset = dataset.map(map_func)\n",
    "\n",
    "# shuffle data and batch it\n",
    "dataset = dataset.shuffle(100000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cafefe1b-567b-4250-b762-65903f46fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = dataset\n",
    "del dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44629fd1-70b8-4d14-b215-a2787442d8a9",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6d2fa-eaa9-4f93-9d89-9b3664645f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "bert = TFAutoModel.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name='attention_mask', dtype='int32')\n",
    "\n",
    "embeddings = bert(input_ids, attention_mask=mask)[0]\n",
    "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, dropout=0.4, recurrent_dropout=0.4, activation='relu'))(embeddings)\n",
    "X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.5)(X)\n",
    "X = tf.keras.layers.Dense(64, activation='relu')(X)\n",
    "X = tf.keras.layers.Dropout(0.3)(X)\n",
    "y = tf.keras.layers.Dense(2, activation='sigmoid', name='outputs')(X)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5965bef6-c801-45c8-904b-ec1d682dcd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 23)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 23)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model_2 (TFDisti TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 32)           100480      tf_distil_bert_model_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          4224        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8256        dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 2)            130         dropout_62[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 66,475,970\n",
      "Trainable params: 66,475,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "111a7cb1-870c-43ed-814c-304cb04aac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()  # categorical = one-hot\n",
    "# acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7b5fc-19b7-4f31-8441-7fce485c0ed9",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a875277c-a1d8-4494-9422-57f5e987007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "324/324 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.6524WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "324/324 [==============================] - 110s 305ms/step - loss: 0.6099 - accuracy: 0.6524 - val_loss: 0.4889 - val_accuracy: 0.7908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebb66a6910>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, validation_data=val, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b022a47-6485-4ac2-9e37-9b9cb09ac4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 102s 315ms/step - loss: 0.4783 - accuracy: 0.7856 - val_loss: 0.4372 - val_accuracy: 0.8138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebb797e5e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, validation_data=val, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149576e7-5e50-4c9b-8bc1-26d19b9f4b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 101s 311ms/step - loss: 0.4023 - accuracy: 0.8331 - val_loss: 0.4617 - val_accuracy: 0.8116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed282ce640>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, validation_data=val, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad1b1ad7-d536-4ae0-aaaa-db8ef3429b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Disaster(text):\n",
    "    text = tokenize(text)\n",
    "    prediction = model.predict(text)\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b56eed-26b6-4c66-9f1b-9ac7c3e6c7b7",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c7c7d7f-c630-4fef-8e8f-a540e92a8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.drop(columns=['keyword', 'location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "26b50d50-42af-4528-ba94-53ae5620a126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   2   \n",
       "2   3   \n",
       "3   9   \n",
       "4  11   \n",
       "\n",
       "                                                                                               text  \n",
       "0                                                                Just happened a terrible car crash  \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.  \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all  \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires  \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4c45807-73f7-4799-ac03-e65442c8be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function defined above to our text\n",
    "test.text=test.text.apply(lambda x:clean_text(x))\n",
    "\n",
    "# Removing stopwords\n",
    "test.text = test.text.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be501d40-e38e-4a88-9e32-1c4dcb02d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['id', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75d3059c-853b-418c-905c-67cb4efbee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.id = test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0159e65-4bf5-4fa2-98ac-6a533892d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34611543-3298-49ba-9fd8-38aa085df949",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, text in enumerate(test.text):\n",
    "    submission.target[index] = Predict_Disaster(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c86d5a0-78c7-4fc1-bd4f-44bb697c62b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id target\n",
       "0         0      1\n",
       "1         2      1\n",
       "2         3      1\n",
       "3         9      1\n",
       "4        11      1\n",
       "...     ...    ...\n",
       "3258  10861      1\n",
       "3259  10865      1\n",
       "3260  10868      1\n",
       "3261  10874      1\n",
       "3262  10875      1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e221f9b-26f1-4852-8f68-dbcf7fcf19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('DistBertWithCleanedDS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3535f-c8d6-453c-a729-3a2c029992e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
